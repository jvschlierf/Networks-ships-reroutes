{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python377jvsc74a57bd0c657ab3134d4d36fa6659201da87ce22dbf2c2b56e557e7a3dd81d87fd1e5788",
   "display_name": "Python 3.7.7 64-bit ('Sim_mod': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Data Preparation \n",
    "Using the Data we got, we have to make some modifications to use in our ABM\n",
    "For example, we clean the routes to only have a single route between two edges"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time, enum, math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pylab as plt\n",
    "from networkx.algorithms.shortest_paths.generic import has_path\n",
    "import networkx as nx\n",
    "import random\n",
    "from tqdm import tqdm, trange\n",
    "\n",
    "data_path = '../' #set to wherever the data files are, will be used on every input"
   ]
  },
  {
   "source": [
    "## Data Imports"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "prev_port      int64\n",
       "next_port      int64\n",
       "distance     float64\n",
       "dtype: object"
      ]
     },
     "metadata": {},
     "execution_count": 41
    }
   ],
   "source": [
    "route_blockages = pd.read_csv((data_path + 'route_blockage.csv'))\n",
    "\n",
    "distances_df = pd.read_csv((data_path + 'distances.csv'))\n",
    "distances = distances_df[[\"prev_port\", \"next_port\", \"distance\"]]\n",
    "distances.astype({'prev_port':'int64', 'next_port':'int64'}).dtypes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_distances = distances.sort_values(by=['prev_port', 'next_port', 'distance'])\n",
    "clean_distances.drop_duplicates(subset=['prev_port', 'next_port'], keep='first', inplace=True, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean_distances.to_csv((data_path + 'clean_distances.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_distances = pd.read_csv((data_path + 'clean_distances.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.from_pandas_edgelist(clean_distances, \"prev_port\", \"next_port\", [\"distance\"], create_using=nx.Graph())\n"
   ]
  },
  {
   "source": [
    "## Create Pruning Plans\n",
    "\n",
    "When cutting the network, we want to ensure that we cut the correct nedges \n",
    "\n",
    "We therefore create a list indicating the number of edges, and then separate the file by which chokepoint (or all) is/are blocked\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "route_blockages_gib =  route_blockages[route_blockages['affected_by_gibraltar']==True]\n",
    "route_blockages_mal =  route_blockages[route_blockages['affected_by_malacca']==True]\n",
    "route_blockages_dov =  route_blockages[route_blockages['affected_by_dover']==True]\n",
    "route_blockages_suez =  route_blockages[route_blockages['affected_by_suez']==True]\n",
    "route_blockages_horm =  route_blockages[route_blockages['affected_by_hormuz']==True]\n",
    "route_blockages_pan = route_blockages[route_blockages['affected_by_panama']==True]\n",
    "\n",
    "route_blockages_horm = route_blockages_horm[[\"prev_port\", \"next_port\"]]\n",
    "route_blockages_gib =  route_blockages_gib[[\"prev_port\", \"next_port\"]]\n",
    "route_blockages_mal =  route_blockages_mal[[\"prev_port\", \"next_port\"]]\n",
    "route_blockages_dov =  route_blockages_dov[[\"prev_port\", \"next_port\"]]\n",
    "route_blockages_suez =  route_blockages_suez[[\"prev_port\", \"next_port\"]]\n",
    "route_blockages_pan = route_blockages_pan[[\"prev_port\", \"next_port\"]]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "route_blockages_total = pd.concat([route_blockages_horm, route_blockages_gib, route_blockages_mal, route_blockages_dov, route_blockages_suez, route_blockages_pan])\n",
    "route_blockages_total = route_blockages_total.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Commented out for your convenience, files are included\n",
    "\"\"\"\n",
    "# route_blockages_horm.to_csv((data_path + 'route_blockages_horm.csv'))\n",
    "# route_blockages_mal.to_csv((data_path + 'route_blockages_mal.csv'))\n",
    "# route_blockages_dov.to_csv((data_path + 'route_blockages_dov.csv'))\n",
    "# route_blockages_suez.to_csv((data_path + 'route_blockages_suez.csv'))\n",
    "# route_blockages_gib.to_csv((data_path + 'route_blockages_gib.csv'))\n",
    "# route_blockages_pan.to_csv((data_path + 'route_blockages_pan.csv'))\n",
    "# route_blockages_total.to_csv((data_path + 'route_blockages_total.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "route_blockages_horm = pd.read_csv((data_path + 'route_blockages_horm.csv'))"
   ]
  },
  {
   "source": [
    "## Pruning Functions"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Cut_Graph(G, route_blockages):\n",
    "    print('Before Pruning',G.number_of_edges())\n",
    "    # CRUCIAL: If the below line is not included, we prune both the additional as well as the ORIGINAL Graphs\n",
    "    return_G = G.copy()\n",
    "    for index in tqdm(range(len(route_blockages)), desc='Removing Edges', delay=0.5):\n",
    "        try:\n",
    "            return_G.remove_edge(route_blockages.iloc[index]['prev_port'],route_blockages.iloc[index]['next_port'])\n",
    "        except:\n",
    "            pass\n",
    "    print('\\n', 'After Pruning',retunr_G.number_of_edges())\n",
    "    return return_G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Build_Cut_Graph(distances, route_blockages):\n",
    "    G = nx.from_pandas_edgelist(distances, \"prev_port\", \"next_port\", [\"distance\"], create_using=nx.Graph())\n",
    "    print('Before Pruning:','\\n','Nodes: ',G.number_of_nodes(), 'Edges: ',G.number_of_edges())\n",
    "    for index in tqdm(range(len(route_blockages)), desc='Removing Edges', delay=0.5):\n",
    "        try:\n",
    "            G.remove_edge(route_blockages.iloc[index]['prev_port'],route_blockages.iloc[index]['next_port'])\n",
    "        except:\n",
    "            pass\n",
    "    print('\\n', 'After Pruning:','\\n', 'Nodes: ',G.number_of_nodes(), 'Edges: ',G.number_of_edges())\n",
    "    return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Before Pruning: \n Nodes:  2912 Edges:  29838\n\n After Pruning: \n Nodes:  2912 Edges:  29365\n"
     ]
    }
   ],
   "source": [
    "G_without_Suez = Build_Cut_Graph(clean_distances, route_blockage_suez)"
   ]
  }
 ]
}